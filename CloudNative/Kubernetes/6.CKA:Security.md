# ApiServer Access Control

- [User Authentication: TLS cert](https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#normal-user)
- [User Authentication: Token](https://kubernetes.io/docs/reference/access-authn-authz/bootstrap-tokens/)
- [Service Account](https://kubernetes.io/docs/concepts/security/service-accounts/)
- [RBAC](https://kubernetes.io/docs/reference/access-authn-authz/rbac/)
- [Admission Controllers](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/)

- ApiServer access control process:

  - user request ->
  - Authentication (who you are) ->
  - Authorization (what you can do) ->
  - Admission Control (provide last-minute access control) ->
  - apiServer approve and fulfill request

- k8s identities: User & ServiceAccount

  - `User Account`: provide id for human user (admins, developers...).
    - User is not a resource in k8s, cannot kubectl get users!
    - User is identified through external reference (HTTP token, HTTPs cert...)
  - `ServiceAccount(sa)`: provide id for application process running inside pod (eg. jenkins).
    - `sa` is a first-class resource in k8s

- User Authentication:

  - `Password Based(deprecated)`: provide base64 encoded username/password in header
  - `Bootstrap Tokens`: provide token in HTTP Header
  - `TLS cert(recommend)`: provide TLS cert, `see TLS section`
  - third-party Auth services

- Authorization (define who can do what)

  - AlwaysAllow: `K8s default`
  - RBAC (Role-Based Access Control): `kubeadm installed k8s default`
  - other:
    - ABAC (Attribute-based authorization ): similar to RBAC, but hard to manage
    - Node: handle Authorization for kubelet (worker nodes). Provide permission for kubelet to apiServer (read pod/nodes, write status, etc...)
    - AlwaysDeny: for debug usage
    - Webhook: use external Authorization instead built-in mechanisms: (eg: send user info + access requirement to external api service => get approved: true/false)
  - chained Authorization: when use multiple Authorizors,
    - pass any of the Authorizors => approved
    - if failed one Authorizors => forward to the next Authorizors

```bash
# /etc/kubernetes/manifests/kube-apiserver.yaml
--authorization-mode=Node,RBAC,Webhook
```

## Authentication: TLS, user account

- Create TLS cert for a User, manually

```bash
# user generate their private key
openssl genrsa -out user-admin.key 2048

# user send CSR with the following info: CN=kube-admin, O=system:maters
openssl req -new -key user-admin.key -out user-admin.csr -subj "/CN=kube-admin/O=system:masters"

# CA administrator receive the CSR and signs certificate in the ca server with ca.key
openssl x509 -req -in user-admin.csr -out user-admin.crt -CA ca.crt -CAkey ca.key -CAcreateserial -days 3650

# CA administrator send back user-admin.crt, and a copy of ca.cert for verifying servers
scp /path/to/user-admin.crt user-node
scp /path/to/ca.cert user-node

# Now in user node
ls
# user-admin.crt  user-admin.csr  user-admin.key  ca.cert

# User can make request to k8s apiServer with TLS certs
curl https://kube-api-server:6443/api/v1/pods \
  --key user-admin.key \
  --cert user-admin.crt \
  --cacert ca.crt \

kubectl get pod \
  --server my-kube:6443 \
  --client-key user-admin.key \
  --client-certificate user-admin.crt \
  --certificate-authority ca.crt
```

### API based Signing: CertificateSigningRequest (csr)

- [doc](https://kubernetes.io/docs/reference/access-authn-authz/certificate-signing-requests/#signer-api)

- CertificateSigningRequest API make it easy for CA admin to sign a CSR (Certificate Signing Request).

  - new user submit a CSR to CA admin
  - CA admin create a CertificateSigningRequest Object (csr), the CertificateSigningRequest object is public for review
  - approve certificate & signing with kubectl command

- CertificateSigningRequest API is fulfilled by `CSR-APPROVING` and `CSR-SIGNING` controller in controller-manager

```bash
# /etc/kubernetes/manifests/hube-controller-manager.yaml
--cluster-signing-cert-file=/path/to/root/ca.crt
--cluster-signing-key-file=/path/to/root/ca.key
```

- demo

```bash
# CA admin receives a 'user-jane123.csr'

# 1. encode user-jane123.csr with base64: <base64-encoded-csr>
cat user-jane123.csr | base64 | tr -d "\n"

# 2. create CertificateSigningRequest config,

# 3. create CertificateSigningRequest
k create -f user-jane123-csr.yml

# 4. review and approve csr
k certificate approve jane123

# 5. extract user's crt, decode crt
k get csr jane123 -o yaml  # "LS0t...."
cat "LS0t...." | base64 --decode > jane123.crt
```

```yml
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: jane123
spec:
  groups:
    - system:authenticated
  signerName: kubernetes.io/kubelet-serving
  usages:
    - digital signature
    - key encipherment
    - server auth
  request: <base64-encoded-csr>
```

### KubeConfig

- KubeConfig

  - provide a config file that store user's tls info centrally
  - allows one-command context switch

- think a password store for different user's password for different website. KubeConfig is a `context` store: for different user's tls certs for different k8s clusters

- Purpose: simplify the use of kubectl with tls (so no need to provide crts/keys every command)

- config location:
  - location can be anywhere is provided path to kubectl
  - default location `~/.kube/config` if no path provided

```bash
# provided path
kubectl get pods --kubeconfig /path/to/config

# the default location, auto-loaded by kubectl if not specifying
~/.kube/config
```

- config template

```yml
# https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/
apiVersion: v1
kind: Config
current-context: admin@my-kube-apiserver # specific the default context for kubectl command

clusters:
  - name: development
    cluster:
      proxy-url: http://proxy.example.org:3128
      server: https://k8s.example.org/k8s/clusters/c-xxyyzz
  - name: my-kube-apiserver
    cluster:
      certificate-authority: /path/to/ca.crt
      # alternative for crt/key files, use -data:
      certificate-authority-data: <base64-encoded-ca.crt>
      server: https://my-kube-apiserver:6443

users:
  - name: admin
    user:
      client-certificate: admin-user.crt
      client-key: admin-user.key

contexts:
  - name: admin@my-kube-apiserver
    context:
      cluster: my-kube-apiserver
      user: admin
      namespace: debug # optional: default ns for a context
```

- kubectl config commands

```bash
# (READ) infos
k config view
k config view --kubeconfig=/path/to/my-conofig  # cat any kubeconfig
k config current-context   # Display the current-context

# change the current context
k config use-context prod-user@prod-cluster

# Write command: useful to create template for kubeconfig file
# (WRITE) add a cluster entry in kubeconfig
k config set-cluster my-kube-apiserver --embed-certs=true --certificate-authority=/path/to/root/ca.crt --server=https://my-kube-apiserver:6443
# (WRITE) add a user entry in kubeconfig
k config set-credentials devman --embed-certs=true --client-certificate=/path/to/devman.crt --client-key=/path/to/devman.key
# (WRITE) add a context entry to kubeconfig
k config set-context devman@my-kube-apiserver --user=devman --cluster=my-kube-apiserver

# (DELETES) Delete cluster
k config delete-cluster
# (DELETES) Delete User
k config delete-user
# (DELETES) Delete context
k config delete-context
```

## Authentication: Service Account(sa)

- [dooc](https://kubernetes.io/docs/concepts/security/service-accounts/)
- [Configure Service Accounts for Pods](https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/)

- Service Account: identity used by an application to interact with a Kubernetes cluster. `Applications must be Authenticated (JWT API token) as Service Account to use kube apis`

  - eg: Prometheus (a monitoring application) uses a service account to pull apiServer for performance metrics.
  - eg: Jenkins uses a service account to deploy application in k8s

- token:
  - every Service Account has a token (JWT API token). (eg. eyJhbG...). The token is stored as a secret
  - for service application deployed inside kubernetes, you can mounted the secret to the target application
  - for service application deployed outside kubernetes, you have to extract the token and config it in the target application

```bash
curl https://192.168,56,70:6443/api -insecure \
  --header "Authorization: Bearer eyJhbG..."
```

- default service account:

  - Every namespace has an automatically generated `default` service account.
  - every pod created in the namespace, if not specified a service account explicitly, will use the default service account
  - the default permission is restricted, only basic read operations

- TokenRequest API vs token secret
  - TokenRequest API is introduced in 1.22 and is recommended over token secret for service account now
  - [token-request](https://kubernetes.io/docs/reference/kubernetes-api/authentication-resources/token-request-v1/)

```bash
# https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/

# create sa
k create sa jenkins-sa
# create a token (with expiring)
k create token jenkins-sa --duration 3600m --audience https://Kubernetes-API-server.com:6443


# create a token secret(without expiring): yml
apiVersion: v1
kind: Secret
type: kubernetes.io/service-account-token
metadata:
  name: jenkins-sa-secret
  annotations:
    kubernetes.io/service-account.name: jenkins-sa
```

```yml
# pod/deployment definition
spec:
  containers:
    - image: jenkins/jenkins
      name: jenkins
  serviceAccountName: jenkins-sa # bind sa:jenkins-sa to a pod
  automountServiceAccountToken: false # do not mount the default service account
---
# bind service account to a role: pod-reader
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: read-pods
  namespace: default
subjects:
  - kind: ServiceAccount
    name: jenkins # Name of service account
    namespace: default
roleRef:
  kind: Role
  name: pod-reader
  apiGroup: rbac.authorization.k8s.io
```

- now you are free to use the generated token in the application, or mount it as a volume to the pod (if deployed in k8s)

```

```

## Authorization: RBAC (Role-Based Access Control)

- RBAC:

  - Identities: User Account/ Service Account/ Group
  - Role: a collection of operation over some resource (permission template: a role is able to do xxx)
  - Binding: bind a role to a Identity

- RBAC identities

  - User: provide id for human user (admins, developers...).
  - ServiceAccount: provide id for application process running inside pod (eg. jenkins).
  - `Group`: a group of User Account or Service Account

- RBAC resources

  - `Role, ClusterRole`: define Roles for accessing single namespace resources/ accessing cluster scope resources
  - `RoleBinding, ClusterRoleBinding`: define binding: identity to Role or ClusterRole

- `cluster scope resources` must use ClusterRole, but ClusterRole is can also use namespace scoped resources
  - nodes, pv, CertificateSigningRequests, ns
-

```bash
k api-resources --namespaced=false # view cluster scope resource
k api-resources --namespaced=true # view namespaced resource
```

```yml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: dev # default ns if not specified
  name: dev-role
rules:
  - apiGroups: [""] # "": core, "*": all, same applied to other rules
    resources: ["pods", "services", "configmaps"]
    verbs: ["get", "list", "watch", "create", "update", "delete"]
    resourceNames: ["blue", "orange"] # optional: specify the resource name that can be used by role
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: dev-role-binding
  namespace: dev
subjects:
  - kind: ServiceAccount # ServiceAccount
    name: <service-account-name>
    namespace: <namespace>
  - kind: User # User defined in rbac.authorization.k8s.io api
    name: Aqua
    apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: dev-role
  apiGroup: rbac.authorization.k8s.io
--- # RoleBinding can also bind an indentity to a ClusterRole
roleRef:
  kind: ClusterRole
  name: cluster-role
  apiGroup: rbac.authorization.k8s.io
```

- use create api

```bash
kubectl create role pod-reader --verb=create,get,list,watch --resource=pods
kubectl create clusterrole storage-admin --verb=* --resource=pv,sc
kubectl create rolebinding admin --clusterrole=admin --user=user1 --user=user2 --group=group1 --serviceaccount=monitoring:sa-dev
kubectl create clusterrolebinding admin --clusterrole=admin --user=user1 --user=user2 --group=group1 --serviceaccount=monitoring:sa-dev
```

- `auth can-i`: check permission as a user

```bash
k auth can-i create deployment
# yes/ no
k auth can-i create deployment --as devman # check permission as a user: devman
```

### API Groups

- API Groups: k8s apiServer 的底层就是一个 HTTP server。API Groups is just routes in the url to group apis

```bash
k api-resources
```

- list of api groups

| route    | name      | included resources                                                | description                           |
| -------- | --------- | ----------------------------------------------------------------- | ------------------------------------- |
| /api/v1  | core api  | ns, pod, nodes, pv, pvc, cm, secrets, services                    |                                       |
| /apis    | named api | /apps, /networking., /storage., /authentication., /certificates., | new features will be add to named api |
| /metrics |           |                                                                   |                                       |
| /healthz |           |                                                                   |                                       |
| /version |           |                                                                   |                                       |
| /logs    |           |                                                                   |                                       |

- apiGroups:
  - `""`: core apis
  - `"*"`: all apis
  - `"apps"`: deploy,...

# TLS for Node Communication

- Requirement: all traffic between nodes must be secure by TLS

- TLS identites in k8s cluster

  - Server Certificate
    - `kube-apiServer`: apiserver.crt, apisever.key
    - `etcd`: etcdserver.crt, etcdserver.key
    - `kubelet`(worker nodes): kubelet.crt, kubelet.key
  - Client Certificate
    - apiServer's client
      - `admin users`: user-admin.crt, user-admin.key
      - `kube-scheduler`: scheduler.crt, scheduler.key
      - `kube-controller-mananger`: controller-mananger.crt, controller-mananger.key
      - `kube-proxy`: kube-proxy.crt, kube-proxy.key
      - `kubelet-client`(worker nodes): kubelet-client.crt, kubelet-client.key
    - etcd's client
      - `kube-apiServer-etcd-client`: apiserver-etcd-client.crt, apisever-etcd-client.key
    - kubelet's client:
      - `kubelet-client` kubelet-client.crt, kubelet-client.key
  - Certificate Authority(CA) in K8s: must be at least 1 CA in k8s cluster
    - ca.crt, ca.key

- !!!!`Kubeadm` provisioned cluster: `automatically generates and configs all necessary TLS certificate`

- [spreadsheet: TLS in k8s info](https://docs.google.com/spreadsheets/d/1_Ul3uSs9DxSoF8vyj5eGaSiU4pTfS82JNhdabePUjmI/edit?usp=sharing)

### Troubleshooting TLS infos in kubeadm cluster

```bash
# in master node: controlplane
ls /etc/kubernetes/manifests # crt/key infos are provided as pod config to different system components

# decode .crt to see certificate content
openssl x509 -in /etc/kubernetes/pki/apiserver.crt -text -noout

# view logs
kubectl logs etcd-master
crictl ps -a
crictl logs containerName 2>&1 | grep ".crt"   # redirect stderr to stdout
docker ps -a
docker logs containerName 2>&1 | grep ".crt"
```

### In action: manually create TLS for k8s Certificate Authority

- [udemy](https://www.udemy.com/course/certified-kubernetes-administrator-with-practice-tests/learn/lecture/14296096)

- Create Certificate Authority(CA)

```bash
# CA private key
openssl genrsa -out ca.key 2048

# CA self-signed CSR
openssl req -new -key ca.key -out ca.csr -subj "/CN=K8S-CA"

# CA self-signed certificate
openssl x509 -req -in ca.csr -signkey ca.key -out ca.crt -days 3650

ls
# ca.crt  ca.csr  ca.key
```

# Private Image Registy

- [Pull an Image from a Private Registry](https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/)

- docker image registries

  - public: docker.io, gcr.io
  - private: aws ecr, azure, gcp, dockerhub

- `docker.io` is the `default public image resource`

  - when use `image: nginx`, k8s automatically append the default soource: `docker.io/library/nginx`

- `docker-registry`: use private image registries in k8s
  - `docker-registry` is a built-in `secret` type for `private image registries credientials`
  - specify the secret in pod definition, then kubelet will use the secret credientials when pulling image

```bash
kubectl create secret docker-registry regcred \
  --docker-server=private-registry.io \
  --docker-username=<your-name> \
  --docker-password=<your-pword> \
  --docker-email=<your-email>
```

```yml
apiVersion: v1
kind: Pod
metadata:
  name: private-reg
spec:
  containers:
    - name: private-reg-container
      image: <your-private-image>
  imagePullSecrets: # !!!
    - name: regcred # name: of docker-registry secret
```

# Security Contexts

- [Security Context](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/)
- process isolation

  - Containers and the host share the same kernel.
  - Containers are isolated using namespaces: host and containers have different namespace
    - processes running inside a container are visable to the host (with a different pid)
    - processes running inside a container cannot see other namespace

- user in container
  - by default the user in container is root, the root however has a limited privilege
  - you can run container with a different user
  - you give root user in container more/less privileges

```bash
# run container as a non-root user
docker run --user=1000 ubuntu sleep 3600

# set user in dockerfile
FROM ubuntu
USER 1000

# give root user in container different privileges
cat /usr/include/linux/capability.h  # see full list of privileges
docker run --cap-add MAC_ADMIN ubuntu sleep 3600
docker run --cap-drop KILL ubuntu sleep 3600
docker run --priviledged ubuntu sleep 3600  # all privileges as the host
```

- `Security Contexts`: set user/ user privileges in pods/containers
  - in k8s, user can be config in pod or container level. if config in pod level, that will affect all containers in the pod. if config in container level, that will override pod level user config
  - user privileges can only be config container level

```yml
apiVersion: v1
kind: Pod
metadata:
  name: security-context-demo
spec:
  securityContext:
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
  containers:
  - name: sec-ctx-demo
    image: busybox:1.28
    command: [ "sh", "-c", "sleep 1h" ]
    securityContext:
      capabilities:
        add: add: ["MAC_ADMIN"]
      allowPrivilegeEscalation: false
```

# Network Policies: Restrict Inter-pod Communication

- [docs](https://kubernetes.io/docs/concepts/services-networking/network-policies/)

- by default Kubernetes use a `all allow rule`:

  - allow traffic from any pod to any other pod or services within the cluster

- Network Policies can restrict these traffic

  - Network Policies is attached to pods, if attached, the affected traffic (Ingress/Egress) will be restricted, otherwise the traffic is free by default

  - Network Policies define Ingress/Egress' `allow targets`
    - in a `ipBlock`
    - in a `namespace`
    - with a `label`
  - Network Policies define `ports that allows` for Ingress/Egress

```yml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: test-network-policy
  namespace: default
spec:
  podSelector: # find pods that applies: use label to
    matchLabels:
      role: db
  policyTypes:
    - Ingress
    - Egress
  ingress: # rule apply to the pods
    - from:
        - ipBlock: # 1. use cidr
            cidr: 172.17.0.0/16
            except:
              - 172.17.1.0/24
        - namespaceSelector: # 2. use namespace
            matchLabels:
              project: myproject
        - podSelector: # 3. use labels
            matchLabels:
              role: frontend
      ports: # ports that allows to connect
        - protocol: TCP
          port: 6379
  egress:
    - to:
        - ipBlock:
            cidr: 10.0.0.0/24
      ports:
        - protocol: TCP
          port: 5978
```
