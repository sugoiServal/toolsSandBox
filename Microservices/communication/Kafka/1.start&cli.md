- resources

  - [quickstart](https://kafka.apache.org/documentation/#quickstart)
  - [image](https://hub.docker.com/r/bitnami/kafka)
  - [manually build cluster](https://www.bilibili.com/video/BV19y4y1b7Uo?p=4)

- API list:
  - `Admin API`: manage and inspect topics, brokers, and other Kafka objects.
  - `Producer API`: publish stream of events
  - `Consumer API`: subscribe, read stream of events
  - `Kafka Streams API`: higher-level functions to stream processing (transformations, aggregations)
  - `Kafka Connect API`: build and run reusable data import/export connectors (from/ to external system)

# TLDR

- Create Cluster
- 创建 `topic` (logical channel of data)
- (test) `producer` push `record` to `topic`
- (test) `consumer` pull `record` from `topic`
- benckmark

### Create Cluster

```bash
curl -sSL https://raw.githubusercontent.com/bitnami/containers/main/bitnami/kafka/docker-compose-cluster.yml > ~/kafka-cluster/docker-compose.yml
docker-compose up -d
docker exec --interactive --tty kafka-cluster-kafka-0-1 /bin/bash   # start interactive in node-0
```

### 创建 `topic` (logical channel of data)

- you can create a topic from any broker node in the cluster
- topic creation process typically involves using the Kafka command-line tools or make API calls to Kafka broker
- Once a topic is created, it becomes visible to all nodes (topic metadata will be updated to all brokers)

```bash
# create topic
kafka-topics.sh --create --topic quickstart-events --bootstrap-server kafka-cluster-kafka-0-1:9092

# list topic
kafka-topics.sh --list --bootstrap-server kafka-cluster-kafka-0-1:9092

# delete topic
kafka-topics.sh --delete --topic java-api-test1 --bootstrap-server kafka-cluster-kafka-0
-1:9092

# describe topic
kafka-topics.sh --describe --topic quickstart-events --bootstrap-server kafka-cluster-kafka-0-1:9092
```

### (test) `producer` push `record` to `topic`

```bash
kafka-console-producer.sh --topic quickstart-events --bootstrap-server kafka-cluster-kafka-0-1:9092
>This is my first event
>This is my second event
# stop the producer client with Ctrl-C at any time.
```

### (test) `consumer` pull `record` from `topic`

```bash
# from any node in the cluster
kafka-console-consumer.sh --topic quickstart-events --from-beginning --bootstrap-server kafka-cluster-kafka-0-1:9092

# stop the producer client with Ctrl-C at any time.
```

### Cluster benckmark test

- [bili](https://www.bilibili.com/video/BV19y4y1b7Uo?p=6&vd_source=c2cab8b68e17f7406c35e588a940b4ae)

```bash
# create benchmark topic (feel free to tweaking the partitions and replication)
kafka-topics.sh --create --topic perf-test --partitions 1 --replication-factor 1 --bootstrap-server kafka-cluster-kafka-0-1:9092


# producer test
kafka-producer-perf-test.sh --topic perf-test --num-records 5000000 --record-size 1024 --throughput -1 --producer-props bootstrap.servers=kafka-cluster-kafka-0-1:9092,kafka-cluster-kafka-1-1:9092,kafka-cluster-kafka-2-1:9092 acks=1
# --throughput -1: 限流，-1不指定

# consumer test
kafka-consumer-perf-test.sh --broker-list kafka-cluster-kafka-0-1:9092,kafka-cluster-kafka-1-1:9092,kafka-cluster-kafka-2-1:9092 --topic perf-test --messages 5000000 --fetch-size 1048576
# --fetch-size 1048576 每次拉取数据大小
# --messages 总共拉取数据数

```

# Setting up Kafka Cluster

- Kafka Cluster can either started using `ZooKeeper` or `KRaft (Kafka Raft, recommend)`
  - these are distributed coordination and synchronization services

### 文件夹

- root
  - bin: .sh for various functionalities (kafka-server-start, kafka-topics, kafka-console-producer...)
  - config: configuration files (server, zookeeper, kraft...)
  - libs: dependencies (Scala/Java)
  - site-docs：帮助文档

```bash
# download https://www.apache.org/dyn/closer.cgi?path=/kafka/3.6.0/kafka_2.13-3.6.0.tgz
wget https://dlcdn.apache.org/kafka/3.6.0/kafka_2.13-3.6.0.tgz
tar -xzf kafka_2.13-3.6.0.tgz
cd kafka_2.13-3.6.0
ls -al
```

### Manually, Zookeeper

- [manually build cluster](https://www.bilibili.com/video/BV19y4y1b7Uo?p=4)

```bash
cd kafka_2.13-3.6.0
vim server.properties   # setting node configurations
    # 1.更改 broker.id: id of node in the cluster. 每一个node的id必须是unique！
    # 2.设置 log.dirs: where kafka data are stored

# start Kraft cluster service
KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"
bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties

# start Kafka server
bin/kafka-server-start.sh config/kraft/server.properties
```

## Dockerized Kafka Cluster

- [image](https://hub.docker.com/r/bitnami/kafka)
- [full doc](https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md)
- [Kubernetes](https://github.com/bitnami/charts/tree/main/bitnami/kafka)

- cluster
  - [Kraft mode configuration](https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md#apache-kafka-kraft-mode-configuration)
  - [setup a Kraft cluster](https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md#setting-up-a-apache-kafka-cluster)

```bash
curl -sSL https://raw.githubusercontent.com/bitnami/containers/main/bitnami/kafka/docker-compose-cluster.yml > docker-compose.yml
docker-compose up -d
```

### Configuration

- modify configuration either through

  - modify docker-compose.yml
  - provide as -e in docker run

```yml
KAFKA_CFG_PROCESS_ROLES: "Comma-separated list of Kafka KRaft roles. Allowed values: controller,broker, controller, broker."
KAFKA_CFG_NODE_ID: "Unique id for the Kafka node."
KAFKA_CFG_LISTENERS: "List of Kafka listeners. If node is set with controller role, the listener CONTROLLER must be included."
KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP: "Maps each listener with a Apache Kafka security protocol. If node is set with controller role, this setting is in order to assign a security protocol for the CONTROLLER LISTENER. E.g.: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT." # "In order to configure controllers communications without authentication, you should provide CONTROLLER:PLAINTEXT
```

### Setup Step-by-step

- volume

```yml
# docker-compose
# https://github.com/bitnami/containers/blob/main/bitnami/kafka/docker-compose.yml
# https://github.com/bitnami/containers/blob/main/bitnami/kafka/docker-compose-cluster.yml

# use volume
# As this is a non-root container, the mounted files and directories must have the proper permissions for the UID 1001.

kafka:
  ...
  volumes:
    - /path/to/kafka-persistence:/bitnami/kafka
  ...
```

- run

```bash
# use network (Containers attached to the same network can communicate with each other using the container name as the hostname.)
docker network create app-tier --driver bridge

# run server node-0
docker run --name kafka-0 \
  --network app-tier \
  -e KAFKA_CFG_NODE_ID=0 \
  -e KAFKA_CFG_PROCESS_ROLES=controller,broker \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093 \
  -e KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3 \
  -e KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3 \
  -e KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv \
  -p :9092 \
  -p :9093 \
  bitnami/kafka:latest

# run server node-1
docker run --name kafka-1 \  # different name
  --network app-tier \
  -e KAFKA_CFG_NODE_ID=1 \      # unique ID
  -e KAFKA_CFG_PROCESS_ROLES=controller,broker \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093 \
  -e KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3 \
  -e KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3 \
  -e KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv \
  -p :9092 \
  -p :9093 \
  bitnami/kafka:latest

# run server node-3
docker run --name kafka-3 \
  --network app-tier \
  -e KAFKA_CFG_NODE_ID=3 \
  -e KAFKA_CFG_PROCESS_ROLES=controller,broker \
  -e KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093 \
  -e KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT \
  -e KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093 \
  -e KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3 \
  -e KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3 \
  -e KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2 \
  -e KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv \
  -p :9092 \
  -p :9093 \
  bitnami/kafka:latest

# run client in interactive mode (-it --rm)
docker run -it --rm \
    --network kafka_cluster_default \
    bitnami/kafka:latest kafka-topics.sh --list  --bootstrap-server kafka-cluster-kafka-0-1:9092
```
