# Architect

- Kafka Client (APIs, process written in any language)

  - `producer`: push record to topic (through broker)
  - `consumer group`
    - `consumer`: pull record from topics (through broker)

- broker

  - node in Kafka cluster, run Kafka process
  - distribute store topic (`partition`, `replicas`)
  - stateless, the state of cluster: maintained with ZooKeeper/Kraft (metadata: topics, partitions, consumer group, leaders...)
  - 100,000/s capability per node

- topic:

  - topic is abstract, a topic is a `collection of partition`,
  - partitions
    - partitions are distributed among brokers
    - a broker can have many partitions, and may from different topics
    - partitions can have `replicas` (followers, promotion on leader failure), replicas are also distributed among brokers

### Replicas

- `leader-follower`: when replicas enabled, each parition has

  - `leader` partition (must be 1): only leader do read and write! read from consumer, write from producer.
  - `follower` partitions (0 or multiple replicas): follower don't read or write. follower sync from leader, and promoted as leader when leader fail

- when we refers to `a partition` in kafka, we generally refers to the `leader partitions`

- ar，isr，osr

  - Assigned Replicas(ar): all replicas
  - In-Sync Replicas(isr): replicas currently in-sync with the leader
  - Out-of-Sync Replicas(osr): replicas currently Out-of-Sync with the leader. 正常运行情况下不应该存在 OSR

- leader election
  - election is based on isr

## Producer

### `idempotence`

- [video](https://www.bilibili.com/video/BV19y4y1b7Uo?p=12)

- idempotence: a property of operations，such that no matter how many times the operation is executed (eg, submit), the result is the same

- enable.idempotence: ensure idempotence, avoid that a producer retries and re-sends the same record multiple time
  - enable.idempotence will slow down the pruduce throughput
  - `acks=all` + `enable.idempotence=true` => maximum durability and guarantee ordered in producer side

```java
props.put("enable.idempotence", "true");
```

### `acks`

- acks is related replicas
- controls what level of acknowledgments the producer requires from the broker after sending a message, before considering the message as "sent" or "committed."
  - acks=0: best efficiency: does not require any acknowledgment from the broker
  - acks=1: balanced: require acknowledgment from the leader partition.
  - acks=all: best durability: requires acknowledgment from all in-sync replicas (ISR) of the partition.

```java
// acks=0: does not require any acknowledgment from the broker: best efficiency
// acks=1: require acknowledgment from the leader partition. balanced
// acks=all: requires acknowledgment from all in-sync replicas (ISR) of the partition. best security
props.put("acks", "all");  // or -1
props.put("acks", "1");
props.put("acks", "0");
```

### `partitioner`

- [video](https://www.bilibili.com/video/BV19y4y1b7Uo?p=13)
- `partitioner`: deciding partition number (in a topic) for each message
- partitioner strategies:
  - api: `ProducerRecord(String topic, Integer partition, K key, V value)`
  - hard-code: when partition is not null: If a producer specifies a partition number in the message record, use it.
  - key-based: when key is provided: If the message provides a key，choose a partition based on a hash value of the key
    - when partition number is fixed, guarantees that same key always send to the same partition. In this case records within a key is `ordered`.
    - when partition number increased/decreased, that same key will be sent to another paritition
    - doesn't ensure that two different keys will never have the same partition
    - if a key contains too many records, partitions would be inbalanced
  - round-robin: when key and partition are null: pick a partition in a round-robin fashion. Records is `not ordered`.
  - custom partitioner: [implement the Partitioner Interface](https://www.learningjournal.guru/courses/kafka/kafka-foundation-training/custom-partitioner/)

```java
props.put("partitioner.class", "CustomPartitioner");
//...
public class CustomPartitioner implements Partitioner {

    public void configure(Map<String, ?> configs) {
        r = new Random();
    }

    public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {

        int numPartitions = cluster.partitionCountForTopic(topic);
        return r.newtInt(1000) % numPartitions;
    }

    public void close() {
    }
}
```

## Consumer

### consumer group

- consumer group

  - consumers with the same `group.id` belongs to the same group
  - `Partitions are not shared` - at any given time, `each partition` of a topic is consumed by only `one consumer`
  - each consumer can consumer
    - multiple topics,
    - multiple partitions
  - partitions and consumer: `Many to One relation`

- `group coordinator`: for each group, `one Kafka broker is elected automatically`, responsible for

  - managing group membership: maintaining a list of active group members and their partition
  - detect state change and `trigger group leader to rebalance`

- `group leader`: The `first consumer` to participate in a consumer group becomes a group leader, responsible for

  - `rebalance` (partition re-assignment)
  - communicate rebalance result to group coordinator

- rebalance:

  - may triggered by:

    - number of consumer change (add/remove)
    - number of partitions change (add/remove)
      - eg: topics consumers subscribe to were deleted

  - rebalance 过程中所有消费者都将停止工作，直到 rebalance 完成

- partition-consumer assignment strategies [讲解](https://www.bilibili.com/video/BV19y4y1b7Uo?p=15)
  - Range(default): 对于 topic, 可确保每个消费者消费的 partition 数量是均衡的
  - Round-Robin: 可确保每个消费者消费的 partition 数量是均衡的
  - Sticky: 确保在 发生 rebalance 后的 partition 尽可能与 rebalance 前相同。没有 rebalance 时与 Round-Robin 类似

```java
props.put("partition.assignment.strategy", "org.apache.kafka.clients.consumer.RoundRobinAssignor");
props.put("partition.assignment.strategy", "org.apache.kafka.clients.consumer.RangeAssignor");
props.put("partition.assignment.strategy", "org.apache.kafka.clients.consumer.StickyAssignor");
```

- in production: set the # of partitions according to the # of available consumers for maximum efficiency

### offset

- offset:

  - offset is relative to a `partition`: represents the last consumed message's location in the partition.
  - offsets' records are stored inside a special internal Kafka topic: `__consumer_offsets`. consumers retrieve offset from the topic
  - avoid process the same record multiple times
    - when consumer-partition ownership change, it tell the new consumer where to start
    - If a consumer fails and rejoins with the same partition (eg, through sticky assignments), it can resume from where it left off.

- there are two types of offsets:

  - `Current offset`: a pointer to the last record that a partition has already sent
    - increment `when a partition sent` the most recent poll to a consumer
  - `Committed Offset`: a pointer to the last record that a consumer has successfully processed
    - increment when a consumer has processed a record and then `commit the offset`

- two ways to `Committed Offset`
  - Auto commit(default): may cause second processing of records
  - Manual-commit:
    - Commit Sync: blocking until commit is acknowledged or or until an error occurs (guarantee process exact once)
    - Commit async: non-blocking, send commit without waiting or retry (not guarantee process exact once)

> Let us understand it with an example.
> You have some messages in the partition, and you made your first poll request. You received 10 messages hence the consumer increases the current offset to 10. You take four seconds to process these ten messages and make a new call. Since you haven't passed five seconds, the consumer will not commit the offset. You received another set of records, and for some reason rebalance is triggered at this moment. First ten records are already processed, but nothing is committed yet. Right? The rebalance is triggered. So, the partition goes to a different consumer. Since we don't have a committed offset, the new owner of partition should start reading from the beginning and process first ten records again.
> You might be thinking that let's reduce the commit frequency to four seconds. You can lower the incidence of commit by setting the auto-commit interval to a lower value, but you can't guarantee to eliminate repeat processing.

- Auto commit

```java
// auto commit

// automatically commit offset
props.setProperty("enable.auto.commit", "true");
// interval of automatically commit offset
props.setProperty("auto.commit.interval.ms", "1000");
    //  If 1000 ms have passed since the previous call, the consumer will auto commit the last offset
```

- manual commit

```java
props.put("enable.auto.commit", "false");

try {
    consumer = new KafkaConsumer<>(props);
    consumer.subscribe(Arrays.asList(topicName));

    while (true) {
        ConsumerRecords<String, Supplier> records = consumer.poll(100);
        for (ConsumerRecord<String, Supplier> record : records) {
            System.out.println("Supplier id= " + String.valueOf(record.value().getID()) +
                    " Supplier  Name = " + record.value().getName() +
                    " Supplier Start Date = " + record.value().getStartDate().toString());
        }
        consumer.commitAsync();
    }
} catch (Exception ex) {
    ex.printStackTrace();
} finally {
    consumer.commitSync();
    consumer.close();
}
```

# Physical Storage

- [video](https://www.bilibili.com/video/BV19y4y1b7Uo/?p=24)
