- [producer](https://www.bilibili.com/video/BV19y4y1b7Uo?p=7)
- [ref](https://kafka.apache.org/36/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html)

- [consumer](https://www.bilibili.com/video/BV19y4y1b7Uo?p=8)
- [ref](https://kafka.apache.org/36/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html)

```xml
<dependency>
    <groupId>org.apache.kafka</groupId>
    <artifactId>kafka-clients</artifactId>
    <version>3.6.0</version>
</dependency>
```

- `demo`: write number 1-100 to a kafka topic

# producer

- [ref](https://kafka.apache.org/36/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html)
- [container issue: accessing-apache-kafka-with-internal-and-external-clients](https://github.com/bitnami/containers/blob/main/bitnami/kafka/README.md#accessing-apache-kafka-with-internal-and-external-clients)
  - [kafka listener](https://rmoff.net/2018/08/02/kafka-listeners-explained/)

```yml
# docker-compose:
# setup external listeners in port 9094
# use node-0 as entry point

# access from external(outside docker network): localhost:9094
# access from internal(outside docker network): kafka-cluster-kafka-0-1:9092

# Copyright VMware, Inc.
# SPDX-License-Identifier: APACHE-2.0

# Copyright VMware, Inc.
# SPDX-License-Identifier: APACHE-2.0

version: "2"

services:
  kafka-0:
    image: docker.io/bitnami/kafka:3.6
    ports:
      - "9092"
      - "9094:9094"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093
      - KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Clustering
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2
    volumes:
      - kafka_0_data:/bitnami/kafka
  kafka-1:
    image: docker.io/bitnami/kafka:3.6
    ports:
      - "9092"
      - "9094"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093
      - KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Clustering
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2
    volumes:
      - kafka_1_data:/bitnami/kafka
  kafka-2:
    image: docker.io/bitnami/kafka:3.6
    ports:
      - "9092"
      - "9094"
    environment:
      # KRaft settings
      - KAFKA_CFG_NODE_ID=2
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka-0:9093,1@kafka-1:9093,2@kafka-2:9093
      - KAFKA_KRAFT_CLUSTER_ID=abcdefghijklmnopqrstuv
      # Listeners
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093,EXTERNAL://:9094
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://:9092,EXTERNAL://localhost:9094
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Clustering
      - KAFKA_CFG_OFFSETS_TOPIC_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=3
      - KAFKA_CFG_TRANSACTION_STATE_LOG_MIN_ISR=2
    volumes:
      - kafka_2_data:/bitnami/kafka

volumes:
  kafka_0_data:
    driver: local
  kafka_1_data:
    driver: local
  kafka_2_data:
    driver: local
```

```java
// https://kafka.apache.org/36/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html
@Slf4j
public class KafkaProducerTest {
    public static void main(String[] args) {
        Properties props = new Properties();

        // create connection config for kafka producer
        props.put("bootstrap.servers", "localhost:9094");

        // use batching: controls the amount of time a producer will wait before sending a batch of messages to a Kafka broker
        props.put("linger.ms", 1);

        // controls the acknowledgment behavior:
            // what level of acknowledgments the producer requires from the broker after sending a message
            // before considering the message as "sent" or "committed."
            // acks=0: does not require any acknowledgment from the broker
            // acks=1: require acknowledgment from the broker
            // acks=all: requires acknowledgment from all in-sync replicas (ISR) of the partition.
        props.put("acks", "all");

        // set serializer to key and value: other options: ProtoBuf, Avro...
        props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
        props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

        Producer<String, String> producer = new KafkaProducer<>(props);

        // use send without callback: Blocking
        // Future<RecordMetadata> send(ProducerRecord<K, V> var1);
        for (int i = 0; i < 100; i++) {
            ProducerRecord<String,String> producerRecord = new ProducerRecord<String, String>("test", Integer.toString(i), Integer.toString(i));
            Future<RecordMetadata> future = producer.send(producerRecord);
            try {
                future.get();
                System.out.println("successfully written the "+ i + "th message.");
            } catch (Exception e) {
                e.printStackTrace();
            }
        }

        // use send with callback: Async, non-blocking
        // Future<RecordMetadata> send(ProducerRecord<K, V> var1, Callback var2);
        for (int i = 0; i < 100; i++) {
            ProducerRecord<String,String> producerRecord = new ProducerRecord<String, String>("test", Integer.toString(i), Integer.toString(i));
            producer.send(producerRecord, new Callback() {
                @Override
                public void onCompletion(RecordMetadata recordMetadata, Exception e) {
                    // check if there are Exception and handle Exception
                    if (e == null) {
                        // successful
                        String topic = recordMetadata.topic();
                        int partition = recordMetadata.partition();
                        long offset = recordMetadata.offset();
                        System.out.printf("topic = %s, partition = %d, offset = %d\n", topic, partition, offset);
                    } else {
                        // unsuccessful
                        System.out.println("Error during message production");
                        log.error(e.getMessage());
                        e.printStackTrace();
                    }
                }
            });
        }

        producer.close();
    }
}
```

# Consumer

```java
// https://kafka.apache.org/36/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html
public class KafkaConsumerTest {
    public static void main(String[] args) {
        Properties props = new Properties();
        props.setProperty("bootstrap.servers", "localhost:9094");

        // consumer group: several consumers in the same group can consume to a topic together: this java process belongs to group test
        props.setProperty("group.id", "test");

        // automatically commit offset
        props.setProperty("enable.auto.commit", "true");

        // interval of automatically commit offset
        props.setProperty("auto.commit.interval.ms", "1000");

        // deserializer
        props.setProperty("key.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");
        props.setProperty("value.deserializer", "org.apache.kafka.common.serialization.StringDeserializer");

        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);

        // a consumer can subscribe to a collection of topics
        consumer.subscribe(Arrays.asList("java-api-test1"));

        // use a loop to pull record from topic constantly
        while (true) {
            // poll a batch of records
            ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(1000));  // poll(timeout duration)
            for (ConsumerRecord<String, String> record : records) {
                System.out.printf("offset = %d, key = %s, value = %s%n", record.offset(), record.key(), record.value());
            }
        }
    }
}
```
